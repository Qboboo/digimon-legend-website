#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°ç å…½ä¼ è¯´ç½‘ç«™ - JSONæ•°æ®è¿ç§»åˆ°SQLæ•°æ®åº“è„šæœ¬
æ”¯æŒMySQLå’ŒPostgreSQL
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime
import logging

# æ•°æ®åº“é©±åŠ¨é€‰æ‹©
try:
    import pymysql
    MYSQL_AVAILABLE = True
except ImportError:
    MYSQL_AVAILABLE = False

try:
    import psycopg2
    import psycopg2.extras
    POSTGRESQL_AVAILABLE = True
except ImportError:
    POSTGRESQL_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class DatabaseMigrator:
    def __init__(self, db_type='mysql', **db_config):
        self.db_type = db_type.lower()
        self.db_config = db_config
        self.connection = None
        self.cursor = None
        
        # é¡¹ç›®è·¯å¾„
        self.project_root = Path(__file__).parent.parent
        self.data_path = self.project_root / 'frontend' / 'js' / 'data'
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            if self.db_type == 'mysql':
                if not MYSQL_AVAILABLE:
                    raise ImportError("è¯·å®‰è£…pymysql: pip install pymysql")
                
                self.connection = pymysql.connect(
                    host=self.db_config.get('host', 'localhost'),
                    user=self.db_config.get('user', 'root'),
                    password=self.db_config.get('password', ''),
                    database=self.db_config.get('database', 'digimon_legend'),
                    charset='utf8mb4',
                    autocommit=False
                )
                
            elif self.db_type == 'postgresql':
                if not POSTGRESQL_AVAILABLE:
                    raise ImportError("è¯·å®‰è£…psycopg2: pip install psycopg2-binary")
                
                self.connection = psycopg2.connect(
                    host=self.db_config.get('host', 'localhost'),
                    user=self.db_config.get('user', 'postgres'),
                    password=self.db_config.get('password', ''),
                    database=self.db_config.get('database', 'digimon_legend'),
                    port=self.db_config.get('port', 5432)
                )
                
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {self.db_type}")
                
            self.cursor = self.connection.cursor()
            logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ° {self.db_type.upper()} æ•°æ®åº“")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨"""
        logger.info("ğŸ”¨ å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
        
        if self.db_type == 'mysql':
            tables = self._get_mysql_tables()
        else:
            tables = self._get_postgresql_tables()
        
        for table_name, create_sql in tables.items():
            try:
                self.cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
                self.cursor.execute(create_sql)
                logger.info(f"âœ… åˆ›å»ºè¡¨ {table_name}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºè¡¨ {table_name} å¤±è´¥: {e}")
                raise
        
        self.connection.commit()
        logger.info("ğŸ‰ æ‰€æœ‰è¡¨åˆ›å»ºå®Œæˆ")
    
    def _get_mysql_tables(self):
        """MySQLè¡¨ç»“æ„"""
        return {
            'digimons': """
                CREATE TABLE digimons (
                    id VARCHAR(50) PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    image VARCHAR(500),
                    positioning VARCHAR(50),
                    type VARCHAR(10),
                    armor VARCHAR(20),
                    fit VARCHAR(10),
                    egg VARCHAR(10),
                    time VARCHAR(20),
                    skills JSON,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            'evolutions': """
                CREATE TABLE evolutions (
                    id VARCHAR(50) PRIMARY KEY,
                    card_data JSON,
                    main_data JSON,
                    stages JSON,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            'equipment': """
                CREATE TABLE equipment (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    dungeon_id VARCHAR(50) NOT NULL,
                    dungeon_name VARCHAR(100) NOT NULL,
                    dungeon_image VARCHAR(500),
                    equipment_sets JSON,
                    loose_items JSON,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    UNIQUE KEY unique_dungeon (dungeon_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            'items': """
                CREATE TABLE items (
                    id VARCHAR(50) PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    category VARCHAR(50),
                    image VARCHAR(500),
                    description TEXT,
                    acquisition_method TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            'synthesis_recipes': """
                CREATE TABLE synthesis_recipes (
                    id VARCHAR(50) PRIMARY KEY,
                    target_item_id VARCHAR(50) NOT NULL,
                    materials JSON,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            'guides': """
                CREATE TABLE guides (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    original_id INT,
                    title VARCHAR(200) NOT NULL,
                    slug VARCHAR(200) UNIQUE NOT NULL,
                    category VARCHAR(50) NOT NULL,
                    difficulty VARCHAR(50),
                    summary TEXT,
                    content LONGTEXT,
                    content_type VARCHAR(20) DEFAULT 'html',
                    status VARCHAR(20) DEFAULT 'draft',
                    update_date DATE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            'changelogs': """
                CREATE TABLE changelogs (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    version VARCHAR(20) UNIQUE NOT NULL,
                    date DATE NOT NULL,
                    changes JSON,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """
        }
    
    def _get_postgresql_tables(self):
        """PostgreSQLè¡¨ç»“æ„"""
        return {
            'digimons': """
                CREATE TABLE digimons (
                    id VARCHAR(50) PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    image VARCHAR(500),
                    positioning VARCHAR(50),
                    type VARCHAR(10),
                    armor VARCHAR(20),
                    fit VARCHAR(10),
                    egg VARCHAR(10),
                    time VARCHAR(20),
                    skills JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """,
            
            'evolutions': """
                CREATE TABLE evolutions (
                    id VARCHAR(50) PRIMARY KEY,
                    card_data JSONB,
                    main_data JSONB,
                    stages JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """,
            
            'equipment': """
                CREATE TABLE equipment (
                    id SERIAL PRIMARY KEY,
                    dungeon_id VARCHAR(50) NOT NULL UNIQUE,
                    dungeon_name VARCHAR(100) NOT NULL,
                    dungeon_image VARCHAR(500),
                    equipment_sets JSONB,
                    loose_items JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """,
            
            'items': """
                CREATE TABLE items (
                    id VARCHAR(50) PRIMARY KEY,
                    name VARCHAR(100) NOT NULL,
                    category VARCHAR(50),
                    image VARCHAR(500),
                    description TEXT,
                    acquisition_method TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """,
            
            'synthesis_recipes': """
                CREATE TABLE synthesis_recipes (
                    id VARCHAR(50) PRIMARY KEY,
                    target_item_id VARCHAR(50) NOT NULL,
                    materials JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """,
            
            'guides': """
                CREATE TABLE guides (
                    id SERIAL PRIMARY KEY,
                    original_id INTEGER,
                    title VARCHAR(200) NOT NULL,
                    slug VARCHAR(200) UNIQUE NOT NULL,
                    category VARCHAR(50) NOT NULL,
                    difficulty VARCHAR(50),
                    summary TEXT,
                    content TEXT,
                    content_type VARCHAR(20) DEFAULT 'html',
                    status VARCHAR(20) DEFAULT 'draft',
                    update_date DATE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """,
            
            'changelogs': """
                CREATE TABLE changelogs (
                    id SERIAL PRIMARY KEY,
                    version VARCHAR(20) UNIQUE NOT NULL,
                    date DATE NOT NULL,
                    changes JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """
        }

    def load_json_data(self, filename):
        """åŠ è½½JSONæ•°æ®æ–‡ä»¶"""
        file_path = self.data_path / filename
        if not file_path.exists():
            logger.warning(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"ğŸ“– æˆåŠŸåŠ è½½ {filename}, æ•°æ®é‡: {len(data) if isinstance(data, (list, dict)) else 'N/A'}")
            return data
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ {filename} å¤±è´¥: {e}")
            return None

    def migrate_digimons(self):
        """è¿ç§»æ•°ç å…½æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»æ•°ç å…½æ•°æ®...")
        data = self.load_json_data('digimon.json')
        if not data:
            return

        for item in data:
            try:
                # å¤„ç†æŠ€èƒ½æ•°æ®
                skills_json = json.dumps(item.get('skills', []), ensure_ascii=False)

                sql = """
                    INSERT INTO digimons (id, name, image, positioning, type, armor, fit, egg, time, skills)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """

                values = (
                    item.get('id'),
                    item.get('name'),
                    item.get('image'),
                    item.get('positioning'),
                    item.get('Type'),  # æ³¨æ„åŸæ•°æ®ä¸­æ˜¯å¤§å†™çš„Type
                    item.get('armor'),
                    item.get('fit'),
                    item.get('egg'),
                    item.get('time'),
                    skills_json
                )

                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥æ•°ç å…½æ•°æ®å¤±è´¥: {e}, æ•°æ®: {item.get('id', 'unknown')}")

        self.connection.commit()
        logger.info(f"âœ… æ•°ç å…½æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def migrate_evolutions(self):
        """è¿ç§»è¿›åŒ–æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»è¿›åŒ–æ•°æ®...")
        data = self.load_json_data('evolutions.json')
        if not data:
            return

        for evo_id, evo_data in data.items():
            try:
                card_data = json.dumps(evo_data.get('card', {}), ensure_ascii=False)
                main_data = json.dumps(evo_data.get('main', {}), ensure_ascii=False)
                stages_data = json.dumps(evo_data.get('stages', []), ensure_ascii=False)

                sql = """
                    INSERT INTO evolutions (id, card_data, main_data, stages)
                    VALUES (%s, %s, %s, %s)
                """

                values = (evo_id, card_data, main_data, stages_data)
                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥è¿›åŒ–æ•°æ®å¤±è´¥: {e}, ID: {evo_id}")

        self.connection.commit()
        logger.info(f"âœ… è¿›åŒ–æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def migrate_equipment(self):
        """è¿ç§»è£…å¤‡æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»è£…å¤‡æ•°æ®...")
        data = self.load_json_data('equipment.json')
        if not data:
            return

        for item in data:
            try:
                equipment_sets = json.dumps(item.get('equipmentSets', []), ensure_ascii=False)
                loose_items = json.dumps(item.get('looseItems', []), ensure_ascii=False)

                sql = """
                    INSERT INTO equipment (dungeon_id, dungeon_name, dungeon_image, equipment_sets, loose_items)
                    VALUES (%s, %s, %s, %s, %s)
                """

                values = (
                    item.get('dungeonId'),
                    item.get('dungeonName'),
                    item.get('dungeonImage'),
                    equipment_sets,
                    loose_items
                )

                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥è£…å¤‡æ•°æ®å¤±è´¥: {e}, å‰¯æœ¬ID: {item.get('dungeonId', 'unknown')}")

        self.connection.commit()
        logger.info(f"âœ… è£…å¤‡æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def migrate_items(self):
        """è¿ç§»ç‰©å“æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»ç‰©å“æ•°æ®...")
        data = self.load_json_data('items.json')
        if not data:
            return

        for item in data:
            try:
                sql = """
                    INSERT INTO items (id, name, category, image, description, acquisition_method)
                    VALUES (%s, %s, %s, %s, %s, %s)
                """

                values = (
                    item.get('id'),
                    item.get('name'),
                    item.get('category'),
                    item.get('image'),
                    item.get('description'),
                    item.get('acquisitionMethod', item.get('acquisition_method'))  # å…¼å®¹ä¸¤ç§å­—æ®µå
                )

                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥ç‰©å“æ•°æ®å¤±è´¥: {e}, ID: {item.get('id', 'unknown')}")

        self.connection.commit()
        logger.info(f"âœ… ç‰©å“æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def migrate_synthesis(self):
        """è¿ç§»åˆæˆé…æ–¹æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»åˆæˆé…æ–¹æ•°æ®...")
        data = self.load_json_data('synthesis.json')
        if not data:
            return

        for item in data:
            try:
                materials = json.dumps(item.get('materials', []), ensure_ascii=False)

                sql = """
                    INSERT INTO synthesis_recipes (id, target_item_id, materials)
                    VALUES (%s, %s, %s)
                """

                values = (
                    item.get('id'),
                    item.get('targetItemId'),
                    materials
                )

                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥åˆæˆé…æ–¹æ•°æ®å¤±è´¥: {e}, ID: {item.get('id', 'unknown')}")

        self.connection.commit()
        logger.info(f"âœ… åˆæˆé…æ–¹æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def migrate_guides(self):
        """è¿ç§»æ”»ç•¥æŒ‡å—æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»æ”»ç•¥æŒ‡å—æ•°æ®...")
        data = self.load_json_data('guides.json')
        if not data:
            return

        for item in data:
            try:
                # å¤„ç†æ—¥æœŸå­—æ®µ
                update_date = None
                if item.get('updateDate'):
                    try:
                        update_date = datetime.strptime(item['updateDate'], '%Y-%m-%d').date()
                    except:
                        pass

                sql = """
                    INSERT INTO guides (original_id, title, slug, category, difficulty, summary,
                                      content, content_type, status, update_date)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """

                values = (
                    item.get('id'),
                    item.get('title'),
                    item.get('slug'),
                    item.get('category'),
                    item.get('difficulty'),
                    item.get('summary'),
                    item.get('content'),
                    item.get('contentType', 'html'),
                    item.get('status', 'draft'),
                    update_date
                )

                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥æ”»ç•¥æ•°æ®å¤±è´¥: {e}, ID: {item.get('id', 'unknown')}")

        self.connection.commit()
        logger.info(f"âœ… æ”»ç•¥æŒ‡å—æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def migrate_changelogs(self):
        """è¿ç§»æ›´æ–°æ—¥å¿—æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹è¿ç§»æ›´æ–°æ—¥å¿—æ•°æ®...")
        data = self.load_json_data('changelog.json')
        if not data:
            return

        for item in data:
            try:
                # å¤„ç†æ—¥æœŸ
                log_date = None
                if item.get('date'):
                    try:
                        log_date = datetime.strptime(item['date'], '%Y-%m-%d').date()
                    except:
                        pass

                changes = json.dumps(item.get('changes', []), ensure_ascii=False)

                sql = """
                    INSERT INTO changelogs (version, date, changes)
                    VALUES (%s, %s, %s)
                """

                values = (
                    item.get('version'),
                    log_date,
                    changes
                )

                self.cursor.execute(sql, values)

            except Exception as e:
                logger.error(f"âŒ æ’å…¥æ›´æ–°æ—¥å¿—æ•°æ®å¤±è´¥: {e}, ç‰ˆæœ¬: {item.get('version', 'unknown')}")

        self.connection.commit()
        logger.info(f"âœ… æ›´æ–°æ—¥å¿—æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {len(data)} æ¡")

    def run_migration(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®è¿ç§»"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»...")
        start_time = datetime.now()

        try:
            # è¿æ¥æ•°æ®åº“
            self.connect()

            # åˆ›å»ºè¡¨
            self.create_tables()

            # è¿ç§»å„ç±»æ•°æ®
            self.migrate_digimons()
            self.migrate_evolutions()
            self.migrate_equipment()
            self.migrate_items()
            self.migrate_synthesis()
            self.migrate_guides()
            self.migrate_changelogs()

            end_time = datetime.now()
            duration = end_time - start_time
            logger.info(f"ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼è€—æ—¶: {duration}")

        except Exception as e:
            logger.error(f"ğŸ’¥ æ•°æ®è¿ç§»å¤±è´¥: {e}")
            if self.connection:
                self.connection.rollback()
            raise
        finally:
            self.close()

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
        logger.info("ğŸ“´ æ•°æ®åº“è¿æ¥å·²å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ æ•°ç å…½ä¼ è¯´ç½‘ç«™ - æ•°æ®è¿ç§»å·¥å…·")
    print("=" * 50)

    # æ•°æ®åº“é…ç½®
    db_configs = {
        'mysql': {
            'host': 'localhost',
            'user': 'root',
            'password': '',  # è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å¯†ç 
            'database': 'digimon_legend'
        },
        'postgresql': {
            'host': 'localhost',
            'user': 'postgres',
            'password': '',  # è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å¯†ç 
            'database': 'digimon_legend',
            'port': 5432
        }
    }

    # é€‰æ‹©æ•°æ®åº“ç±»å‹
    print("è¯·é€‰æ‹©æ•°æ®åº“ç±»å‹:")
    print("1. MySQL")
    print("2. PostgreSQL")

    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()

    if choice == '1':
        db_type = 'mysql'
        if not MYSQL_AVAILABLE:
            print("âŒ è¯·å…ˆå®‰è£…MySQLé©±åŠ¨: pip install pymysql")
            return
    elif choice == '2':
        db_type = 'postgresql'
        if not POSTGRESQL_AVAILABLE:
            print("âŒ è¯·å…ˆå®‰è£…PostgreSQLé©±åŠ¨: pip install psycopg2-binary")
            return
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return

    # è·å–æ•°æ®åº“é…ç½®
    config = db_configs[db_type].copy()

    print(f"\nå½“å‰é…ç½® ({db_type.upper()}):")
    for key, value in config.items():
        if key == 'password':
            display_value = '*' * len(value) if value else '(ç©º)'
        else:
            display_value = value
        print(f"  {key}: {display_value}")

    # ç¡®è®¤æ˜¯å¦ä¿®æ”¹é…ç½®
    modify = input("\næ˜¯å¦éœ€è¦ä¿®æ”¹é…ç½®? (y/N): ").strip().lower()
    if modify == 'y':
        for key in config.keys():
            if key == 'password':
                new_value = input(f"è¯·è¾“å…¥ {key} (å½“å‰: {'*' * len(config[key]) if config[key] else '(ç©º)'}): ").strip()
            else:
                new_value = input(f"è¯·è¾“å…¥ {key} (å½“å‰: {config[key]}): ").strip()

            if new_value:
                if key == 'port':
                    config[key] = int(new_value)
                else:
                    config[key] = new_value

    # ç¡®è®¤å¼€å§‹è¿ç§»
    print(f"\nå‡†å¤‡è¿ç§»æ•°æ®åˆ° {db_type.upper()} æ•°æ®åº“...")
    confirm = input("ç¡®è®¤å¼€å§‹è¿ç§»? (y/N): ").strip().lower()
    if confirm != 'y':
        print("âŒ è¿ç§»å·²å–æ¶ˆ")
        return

    # æ‰§è¡Œè¿ç§»
    migrator = DatabaseMigrator(db_type, **config)
    migrator.run_migration()


if __name__ == '__main__':
    main()
